import joblib
import keras
import pandas as pd
import CTCN_MODEL_TRAIN.Read_DataSet
import numpy as np
from keras.utils import np_utils
from keras.layers import Dense, Dropout, Input
from keras.layers.recurrent import LSTM
from keras.layers import LeakyReLU
import matplotlib.pyplot as plt
import tensorflow as tf
import pickle
from keras import Input, Model
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

from keras.layers import Conv1D, LeakyReLU, add, Activation, Flatten, Dense, Dropout
from sklearn.ensemble import GradientBoostingRegressor
from timeit import default_timer as timer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.optimizers import adam_v2

def Read_Excel():
    p_num = 76
    p_tnum = 85
    p_length = 118

    data_A = CTCN_MODEL_TRAIN.Read_DataSet.get_data('dataset.xlsx', 'Sheet1')
    data_A = MinMaxScaler().fit_transform(data_A)
    label_A = CTCN_MODEL_TRAIN.Read_DataSet.get_data('dataset.xlsx', 'Sheet1',9)

    dataset_split = p_num * p_length
    # 模型训练集数目和标签 Model training dataset number and labels
    train_data = data_A[:dataset_split - 1]
    train_label = label_A[:dataset_split - 1]

    # 模型测试集中某118个连续数据项和标签   The  118 continuous data items and labels in the model test dataset
    test_data = data_A[dataset_split:p_length * p_tnum]
    test_label = label_A[dataset_split:len(data_A)]

    train_data = train_data.reshape(-1, 1, 9)
    test_data = test_data.reshape(-1, 1, 9)
    return train_data, test_data, train_label, test_label


optimizer = adam_v2.Adam(0.0002, 0.5)

def GBDT_PREDICTION():
    train_data, test_data, train_label, test_label = Read_Excel()
    gbdt = GradientBoostingRegressor( n_estimators=500, criterion='mse', learning_rate=0.1, min_samples_split=2, min_samples_leaf=1, max_depth=6)
    gbdt.fit(train_data, train_label)
    joblib.dump(gbdt,'D:/Pthird_nn/My_TCN_GBDT_Dataset/'+'GBDT_PREDICTION_result.m')
    gbdt = joblib.load('D:/Pthird_nn/My_TCN_GBDT_Dataset/GBDT_PREDICTION_result.m')
    start = timer()
    Prediction_data = gbdt.predict(test_data)
    end1 = timer()
    a = RMSE_Model(test_label,Prediction_data)
    b = MAE_Model(test_label,Prediction_data)
    R2 =r2_score(Prediction_data, test_label)
    # c = RMAPE_Model(test_label,Prediction_data)
    # R2 = R_Cofficient(Prediction_data,test_data)
    print('RMSE',a,'MAE',b,"R2",R2, 'time', end1-start)

    print(test_label.shape,Prediction_data.shape)

def show_picture(test_label, Prediction_data):
    plt.figure()
    # 1*1 的网络，第一幅子图
    plt.plot(range(len(test_label)),test_label, linestyle='-',  color='r', linewidth=1,marker='o',markersize=3,  label="Actual_data")
    plt.plot(range(len(Prediction_data)),Prediction_data,linestyle='-',  color='b', linewidth=1,marker='o',markersize=3,  label="Prediction_data")
    plt.show()

def RMSE_Model(Prediction_data, test_label):

    rmse = np.sqrt(mean_squared_error(Prediction_data, test_label))
    return rmse

def MAE_Model(Prediction_data, test_label):
    # error = []
    # for i in range(len(Prediction_data)):
    #     error.append(abs(Prediction_data[i] - test_label[i]))

    # mae = np.average(np.abs(Prediction_data - test_label))
    mae = mean_absolute_error(Prediction_data,test_label)
    return mae




# def show_train_history(train_history, train, validation):
#     plt.plot(train_history.history[train])
#     plt.plot(train_history.history[validation])
#     plt.title('Train_history')
#     plt.ylabel(train)
#     plt.yscale('log')
#     plt.xlabel('Epoch')
#     plt.legend(['train', 'validation'], loc = 'upper left')
#     plt.show()


# show_train_history(train_history, 'loss', 'val_loss')





if __name__ == '__main__':
    GBDT_PREDICTION()
    # TCN_PREDICTION()
