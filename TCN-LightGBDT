
w.python.keras.layers import BatchNormalization
import lightgbm as lgb
from sklearn.ensemble import GradientBoostingRegressor
import CTCN_MODEL_TRAIN.Read_DataSet
from keras import Input, Model
import matplotlib.pyplot as plt
import  os
from keras.optimizers import adam_v2
from keras.layers import Conv1D, LeakyReLU, add, Activation, Flatten, Dense, Dropout

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

from timeit import default_timer as timer


# 读取数据集数据 Read the data in dataset file
def Read_Excel():
    p_num = 76
    p_tnum = 85
    p_length = 118

    data_A = CTCN_MODEL_TRAIN.Read_DataSet.get_data('dataset.xlsx', 'Sheet4')
    data_A = MinMaxScaler().fit_transform(data_A)
    label_A = CTCN_MODEL_TRAIN.Read_DataSet.get_label('dataset.xlsx', 'Sheet4',9)

    dataset_split = p_num * p_length
    #模型训练集数目和标签 Model training dataset number and labels
    train_data=data_A[:dataset_split-1]
    train_label=label_A[:dataset_split-1]

    # 模型测试集中某118个连续数据项和标签   The  118 continuous data items and labels in the model test dataset
    test_data = data_A[dataset_split:p_length * p_tnum]
    test_label = label_A[dataset_split:len(data_A)]

    train_data = train_data.reshape(-1,1,9)
    test_data = test_data.reshape(-1,1,9)
    return train_data, test_data, train_label,test_label

optimizer = adam_v2.Adam(0.0002, 0.5)
optimizer = adam_v2.Adam(0.0002, 0.5)
# 构建TCN膨胀卷积层模型
# 构建TCN膨胀卷积层模型
def ResBlock(x,filters,kernel_size,dilation_rate):
    r = Conv1D(filters,kernel_size,padding='same',dilation_rate=dilation_rate)(x)
    r = Activation('relu')(r)
    r = Dropout(0.15)(r)
    r = Conv1D(filters, kernel_size, padding='same', dilation_rate=dilation_rate)(r)
    r = Activation('relu')(r)
    r = Dropout(0.15)(r)
    if x.shape[-1] ==filters:
        shortcut = x
    else:
        #降维1/r的比率

        shortcut = Conv1D(filters,kernel_size=1,padding='same')(x)
    #  输出和原始输入相加
    o = add([r, shortcut])
    o = Activation('relu')(o)
    return o


def STCN_PREDICTION():

    # STCN 特征提取
    inputs = Input(shape=(1, 9))
    x = ResBlock(inputs, filters=128, kernel_size=2, dilation_rate=1)
    x = ResBlock(x, filters=64, kernel_size=2, dilation_rate=2)
    x = ResBlock(x, filters=32, kernel_size=2, dilation_rate=4)
    x = ResBlock(x, filters=16, kernel_size=2, dilation_rate=8)
    x = ResBlock(x, filters=16, kernel_size=2, dilation_rate=16)
    c1 = Flatten()(x)
    c2 = Dense(units=32)(c1)
    c3 = LeakyReLU(alpha=0.15)(c2)
    c4 = Dropout(0.15)(c3)
    outputs = Dense(units=16)(c4)
    return Model(inputs, outputs)


    # print(model.summary())
    # model.fit(train_data, train_label, validation_split=0.1, epochs=500, batch_size=50, verbose=2)
    # model.save('D:/Pthird_nn/My_TCN_GBDT_Dataset/' + 'TCN_PREDICTION_Model.h5')
def LIGHT_GBDT(train_features, train_labels):
    # Light_GBM = lgb.LGBMRegressor(n_estimators= 500, metric='mse',learning_rate=0.1,max_depth=6, bagging_fraction = 0.5,feature_fraction = 0.9)

    gbdt = GradientBoostingRegressor(n_estimators=500, criterion='mse', learning_rate=0.1, max_depth=6)
    gbdt.fit(train_features, train_labels)
    # Light_GBM.fit(train_features, train_labels)
    # return Light_GBM
    return gbdt

def show_picture(test_label, Prediction_data):
    plt.figure()
    # 1*1 的网络，第一幅子图
    plt.plot(range(len(test_label)),test_label, linestyle='-',  color='r', linewidth=1,marker='o',markersize=3,  label="Actual_data")
    plt.plot(range(len(Prediction_data)),Prediction_data,linestyle='-',  color='b', linewidth=1,marker='o',markersize=3,  label="Prediction_data")
    plt.show()
    
    
# RMSE metrics function
def RMSE_Model(Prediction_data, test_label):

    rmse = np.sqrt(mean_squared_error(Prediction_data, test_label))
    return rmse
#MAE metrics function
def MAE_Model(Prediction_data, test_label):

    mae = mean_absolute_error(Prediction_data,test_label)
    return mae

#模型主体预测
train_data, test_data, train_label, test_label, train_data_all,train_label_all= Read_Excel()
# TCN_Extracted = STCN_PREDICTION()
# TCN_Extracted.compile(loss='mse', optimizer=optimizer)
# TCN_Extracted.fit(train_data, train_label, validation_split=0.1, epochs=500, batch_size=50, verbose=2)
# TCN_Extracted.save('D:/Pthird_nn/My_TCN_GBDT_Dataset/' + 'NON_TCN_PREDICTION_GBDT_Model.h5')

TCN_Extracted = load_model('D:/Pthird_nn/My_TCN_GBDT_Dataset/NON_TCN_PREDICTION_GBDT_Model.h5')
Features_Data_1 = TCN_Extracted.predict(train_data)
start = timer()
Features_Data_2 = TCN_Extracted.predict(test_data)
end1 = timer()
Light_gbdt = LIGHT_GBDT(Features_Data_1, train_label)
end2 = timer()
Final_Prediction = Light_gbdt.predict(Features_Data_2)
end3 = timer()

RMSE = RMSE_Model(Final_Prediction, test_label)
MAE = MAE_Model(Final_Prediction, test_label)
R2 = r2_score(Final_Prediction, test_label)
print("RMSE", RMSE, "MAE", MAE,"R2", R2)

print(end3-start-(end2-end1))
